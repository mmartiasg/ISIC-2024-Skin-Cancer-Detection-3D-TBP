{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-17T21:08:41.487432Z",
     "start_time": "2024-08-17T21:08:40.896Z"
    }
   },
   "source": [
    "import json\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prototypes.classical.dataloader.Loader import IsiCancerData\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "with open(\"../config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T21:08:52.334841Z",
     "start_time": "2024-08-17T21:08:41.488523Z"
    }
   },
   "cell_type": "code",
   "source": "train_csv = pd.read_csv(config[\"TRAIN_METADATA\"], engine=\"python\")",
   "id": "fd62122f982a1b2d",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T21:17:17.386375Z",
     "start_time": "2024-08-17T21:16:59.769007Z"
    }
   },
   "cell_type": "code",
   "source": "dict_target = pd.read_csv(config[\"TRAIN_METADATA\"], engine=\"python\")[[\"isic_id\", \"target\"]]",
   "id": "e3857727b59cbbf9",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T21:17:17.484204Z",
     "start_time": "2024-08-17T21:17:17.387447Z"
    }
   },
   "cell_type": "code",
   "source": "dict_target = dict(zip(dict_target[\"isic_id\"].values, dict_target[\"target\"].values))",
   "id": "5764b4b51a7d5069",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T21:17:17.512347Z",
     "start_time": "2024-08-17T21:17:17.485037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "list(dict_target.keys())[:5]"
   ],
   "id": "899714e9e3473682",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T21:17:17.527146Z",
     "start_time": "2024-08-17T21:17:17.513350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "dict_target[\"ISIC_0015670\"]"
   ],
   "id": "b6094ab81808bd06",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:30:19.976368Z",
     "start_time": "2024-08-12T19:30:19.966335Z"
    }
   },
   "cell_type": "code",
   "source": "train_csv.shape",
   "id": "f9053c71c9c7d284",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:30:20.020180Z",
     "start_time": "2024-08-12T19:30:19.977291Z"
    }
   },
   "cell_type": "code",
   "source": "train_csv.sample(n=1000)",
   "id": "cf12f4e7b74def94",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data balance\n",
    "\n",
    "- Imbalanced Dataset: Specifically refers to unequal class distribution in classification problems.\n",
    "- Unbalanced Dataset: A more general term that might refer to any irregularity or inconsistency in the dataset, including but not limited to class imbalance."
   ],
   "id": "56106a2939e1cbdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:30:20.036726Z",
     "start_time": "2024-08-12T19:30:20.021554Z"
    }
   },
   "cell_type": "code",
   "source": "train_csv.groupby(by=\"target\")[[\"target\"]].count()/len(train_csv)",
   "id": "fcf388c199b94306",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This dataset is imbalance. The unhealthy class is not even 1% of the whole dataset.",
   "id": "70035c4b07c80195"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:30:20.065095Z",
     "start_time": "2024-08-12T19:30:20.037538Z"
    }
   },
   "cell_type": "code",
   "source": "train_csv.query(\"target==1\").head(5)",
   "id": "659b70a01202a427",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:30:23.497820Z",
     "start_time": "2024-08-12T19:30:20.065981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from prototypes.classical.descriptors.texture import LBPTransformer, HoGTransformer, GaborTransformer\n",
    "\n",
    "lbp_transformer = LBPTransformer(p=1, r=8)\n",
    "hog_transformer = HoGTransformer(orientations=8, pixels_per_cell=(8, 8), cells_per_block=(8, 8), visualize=True)\n",
    "gabor_transformer = GaborTransformer(frequency=1/100, theta=np.pi/4, sigma_x=5, sigma_y=5)\n",
    "\n",
    "fig, ax = plt.subplots(4, 2, figsize=(15, 25))\n",
    "\n",
    "for i in range(4):\n",
    "    cancer_image_file_name = train_csv.query(\"target==1\").to_numpy()[i][0] + \".jpg\"\n",
    "    non_cancer_image_file_name = train_csv.query(\"target==0\").to_numpy()[i][0] + \".jpg\"\n",
    "    \n",
    "    cancer_image = cv2.imread(os.path.join(config[\"TRAIN_IMAGES_PATH\"], cancer_image_file_name), cv2.IMREAD_COLOR)[:,:,::-1]\n",
    "    non_cancer_image = cv2.imread(os.path.join(config[\"TRAIN_IMAGES_PATH\"], non_cancer_image_file_name), cv2.IMREAD_COLOR)[:,:,::-1]\n",
    "    \n",
    "    ax[i, 0].imshow(cancer_image)\n",
    "    ax[i, 0].set_title(\"Cancer image\")\n",
    "    \n",
    "    ax[i, 1].imshow(non_cancer_image)\n",
    "    ax[i, 1].set_title(\"Healthy image\")"
   ],
   "id": "e9651319461d5050",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:30:33.871680Z",
     "start_time": "2024-08-12T19:30:23.498673Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = IsiCancerData(config)",
   "id": "a745b4aacfacb25a",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Texture Study",
   "id": "39dfb5c82d58dd96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:30:41.442901Z",
     "start_time": "2024-08-12T19:30:33.872626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMAGES = 10\n",
    "fig, ax = plt.subplots(IMAGES, 8, figsize=(30, 40))\n",
    "\n",
    "for i in range(IMAGES):\n",
    "    image, labels = dataset.get_item()\n",
    "\n",
    "    gabor_transformer = GaborTransformer(frequency=1/100, theta=np.pi/4, sigma_x=5, sigma_y=5)\n",
    "    lbp_transformer = LBPTransformer(p=8, r=1)\n",
    "    hog_transformer = HoGTransformer(orientations=8,\n",
    "                                     pixels_per_cell=(8, 8),\n",
    "                                     cells_per_block=(2, 2),\n",
    "                                     visualize=True)\n",
    "    \n",
    "    ax[i, 0].imshow(image[:, :, ::-1])\n",
    "    ax[i, 0].set_title(\"Original Image\")\n",
    "    ax[i, 1].imshow(lbp_transformer.transform(image))\n",
    "    ax[i, 1].set_title(\"LBP Transform\")\n",
    "    ax[i, 2].imshow(hog_transformer.transform(image)[1])\n",
    "    ax[i, 2].set_title(\"HoG Transform\")\n",
    "    \n",
    "    gabor_map = gabor_transformer.transform(image)\n",
    "    gabor_magnitude = np.sqrt(gabor_map[0]**2 + gabor_map[1]**2)\n",
    "    \n",
    "    ax[i, 3].imshow(gabor_map[0])\n",
    "    ax[i, 3].set_title(\"Gabor Real Part\")\n",
    "    ax[i, 4].imshow(gabor_map[1])\n",
    "    ax[i, 4].set_title(\"Gabor Imaginary Part\")\n",
    "    ax[i, 5].imshow(gabor_magnitude)\n",
    "    ax[i, 5].set_title(\"Gabor Magnitude Part\")\n",
    "    \n",
    "    imag_attention_map = image.copy()\n",
    "    \n",
    "    imag_attention_map[:, :, 0] = imag_attention_map[:, :, 0] * (gabor_map[1] > 0)\n",
    "    imag_attention_map[:, :, 1] = imag_attention_map[:, :, 1] * (gabor_map[1] > 0)\n",
    "    imag_attention_map[:, :, 2] = imag_attention_map[:, :, 2] * (gabor_map[1] > 0)\n",
    "    \n",
    "    magnitude_attention_map = image.copy()\n",
    "    \n",
    "    magnitude_attention_map[:, :, 0] = magnitude_attention_map[:, :, 0] * (gabor_magnitude > 0)\n",
    "    magnitude_attention_map[:, :, 1] = magnitude_attention_map[:, :, 1] * (gabor_magnitude > 0)\n",
    "    magnitude_attention_map[:, :, 2] = magnitude_attention_map[:, :, 2] * (gabor_magnitude > 0)\n",
    "    \n",
    "    ax[i, 6].imshow(imag_attention_map[:, :, ::-1])\n",
    "    ax[i, 6].set_title(\"Gabor Imaginary Attention\")\n",
    "    ax[i, 7].imshow(magnitude_attention_map[:, :, ::-1])\n",
    "    ax[i, 7].set_title(\"Gabor Magnitude Attention\")"
   ],
   "id": "f4dd2f3bc27d5e0e",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gabor bank feature vector",
   "id": "8603e954e921db7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:30:42.203891Z",
     "start_time": "2024-08-12T19:30:41.443806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset.reset_index()\n",
    "\n",
    "image, labels = dataset.get_item()\n",
    "\n",
    "image = cancer_image\n",
    "\n",
    "gabor_transformer = GaborTransformer(frequency=1/100, theta=np.pi/4, sigma_x=5, sigma_y=5)\n",
    "lbp_transformer = LBPTransformer(p=8, r=1)\n",
    "\n",
    "gabor_filter_bank = gabor_transformer.transform(image)\n",
    "\n",
    "imag_attention_map = image.copy()\n",
    "imag_attention_map[:, :, 0] = imag_attention_map[:, :, 0] * (gabor_filter_bank[1] > 0)\n",
    "imag_attention_map[:, :, 1] = imag_attention_map[:, :, 1] * (gabor_filter_bank[1] > 1)\n",
    "imag_attention_map[:, :, 2] = imag_attention_map[:, :, 2] * (gabor_filter_bank[1] > 2)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(image[:, :, ::-1])\n",
    "ax[1].imshow(imag_attention_map)\n",
    "ax[2].imshow(lbp_transformer.transform(gabor_filter_bank[1]))\n",
    "ax[3].imshow(lbp_transformer.transform(imag_attention_map))"
   ],
   "id": "8bec263a52e527eb",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gabor banks to describe malignant and benignant tumors\n",
    "\n",
    "The idea here is to extract information about each image in terms of distribution mean, std/\n",
    "\n",
    "Find any statistical differences (CI of 90%) that will help me to identify the anomalies (malignant tumors)"
   ],
   "id": "4dce75594d9d0237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:30:42.207471Z",
     "start_time": "2024-08-12T19:30:42.207150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gabor_filter_bank = [GaborTransformer(frequency=1/100, theta=theta, sigma_x=5, sigma_y=5) for theta in [np.pi, np.pi/4, np.pi/8, np.pi/16, np.pi/32]]\n",
    "\n",
    "IMAGE_WIDTH = IMAGE_HEIGHT = int(config[\"IMAGE_WIDTH\"])\n",
    "\n",
    "filter_bank_magnitude = np.zeros((len(train_csv.query(\"target==1\")) * len(gabor_filter_bank), IMAGE_WIDTH, IMAGE_WIDTH))\n",
    "filter_bank_imaginary = np.zeros((len(train_csv.query(\"target==1\")) * len(gabor_filter_bank), IMAGE_WIDTH, IMAGE_WIDTH))\n",
    "filter_bank_real = np.zeros((len(train_csv.query(\"target==1\")) * len(gabor_filter_bank), IMAGE_WIDTH, IMAGE_WIDTH))\n",
    "\n",
    "offset = 0\n",
    "for i in tqdm(range(len(train_csv.query(\"target==1\")))):\n",
    "    cancer_image_file_name = train_csv.query(\"target==1\").to_numpy()[i][0] + \".jpg\"    \n",
    "    cancer_image = cv2.imread(os.path.join(config[\"TRAIN_IMAGES_PATH\"], cancer_image_file_name), cv2.IMREAD_COLOR)[:, :, ::-1]\n",
    "    cancer_image = cv2.resize(cancer_image, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    for j, filter in enumerate(gabor_filter_bank):\n",
    "        real, img = filter.transform(cancer_image) \n",
    "        filter_bank_magnitude[i+j+offset] = np.sqrt(real**2 + img**2)\n",
    "        filter_bank_imaginary[i+j+offset] = img\n",
    "        filter_bank_real[i+j+offset] = real\n",
    "        \n",
    "    offset += len(gabor_filter_bank)-1"
   ],
   "id": "f186a158c1184a8f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:30:42.208527Z",
     "start_time": "2024-08-12T19:30:42.208158Z"
    }
   },
   "cell_type": "code",
   "source": "filter_bank_imaginary[-1].sum()",
   "id": "8de6770b59c0e0d5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(5, 3, figsize=(5, 10))\n",
    "\n",
    "# 0 the 1st image\n",
    "offset = 0\n",
    "for i in range(offset, offset+5):\n",
    "    ax[i, 0].imshow(filter_bank_real[i])\n",
    "    ax[i, 1].imshow(filter_bank_imaginary[i])\n",
    "    ax[i, 2].imshow(filter_bank_magnitude[i])"
   ],
   "id": "8759cf63c37077f6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filter_bank_real[10].shape",
   "id": "58dd6ff052ab5ab5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gabor_filter_bank = [GaborTransformer(frequency=1/100, theta=theta, sigma_x=5, sigma_y=5) for theta in [np.pi, np.pi/4, np.pi/8, np.pi/16, np.pi/32]]\n",
    "\n",
    "IMAGE_WIDTH = IMAGE_HEIGHT = int(config[\"IMAGE_WIDTH\"])\n",
    "\n",
    "filter_bank_magnitude_non_malignant = np.zeros((len(train_csv.query(\"target==0\").head(1000)) * len(gabor_filter_bank), IMAGE_WIDTH, IMAGE_WIDTH))\n",
    "filter_bank_imaginary_non_malignant = np.zeros((len(train_csv.query(\"target==0\").head(1000)) * len(gabor_filter_bank), IMAGE_WIDTH, IMAGE_WIDTH))\n",
    "filter_bank_real_non_malignant = np.zeros((len(train_csv.query(\"target==0\").head(1000)) * len(gabor_filter_bank), IMAGE_WIDTH, IMAGE_WIDTH))\n",
    "\n",
    "offset = 0\n",
    "for i in tqdm(range(len(train_csv.query(\"target==0\").head(1000)))):\n",
    "    cancer_image_file_name = train_csv.query(\"target==0\").to_numpy()[i][0] + \".jpg\"    \n",
    "    cancer_image = cv2.imread(os.path.join(config[\"TRAIN_IMAGES_PATH\"], cancer_image_file_name), cv2.IMREAD_COLOR)[:, :, ::-1]\n",
    "    cancer_image = cv2.resize(cancer_image, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    for j, filter in enumerate(gabor_filter_bank):\n",
    "        real, img = filter.transform(cancer_image) \n",
    "        filter_bank_magnitude_non_malignant[i+j+offset] = np.sqrt(real**2 + img**2)\n",
    "        filter_bank_imaginary_non_malignant[i+j+offset] = img\n",
    "        filter_bank_real_non_malignant[i+j+offset] = real\n",
    "\n",
    "    offset += len(gabor_filter_bank)-1"
   ],
   "id": "46f01bc709f6a89a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(5, 3, figsize=(5, 10))\n",
    "\n",
    "# 0 the 1st image\n",
    "offset = 0\n",
    "for i in range(offset, offset+5):\n",
    "    ax[i, 0].imshow(filter_bank_real_non_malignant[i])\n",
    "    ax[i, 1].imshow(filter_bank_imaginary_non_malignant[i])\n",
    "    ax[i, 2].imshow(filter_bank_magnitude_non_malignant[i])"
   ],
   "id": "96849c9cafd60cd4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filter_bank_imaginary_non_malignant[filter_bank_imaginary_non_malignant>0].mean(),filter_bank_imaginary_non_malignant[filter_bank_imaginary_non_malignant>0].std()",
   "id": "8deef36e6dba98ce",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filter_bank_real_non_malignant.mean(),filter_bank_real_non_malignant.std()",
   "id": "8d17d01004596c81",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filter_bank_magnitude_non_malignant.mean(),filter_bank_magnitude_non_malignant.std()",
   "id": "9d2eb26fc68f5da9",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filter_bank_imaginary[filter_bank_imaginary>0].mean(),filter_bank_imaginary[filter_bank_imaginary>0].std()",
   "id": "9e5db082d9bdbff2",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filter_bank_real.mean(),filter_bank_real.std()",
   "id": "34e83f154ebdd835",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filter_bank_magnitude.mean(),filter_bank_magnitude.std()",
   "id": "dc2a3995a9358947",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# remove the most common color of each image\n",
    "\n",
    "Most of the surface of the image is covered by skin the lesion is just an small part of the image"
   ],
   "id": "8bfca50249013881"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cancer_image_file_name = train_csv.query(\"target==1\").to_numpy()[100][0] + \".jpg\"\n",
    "\n",
    "cancer_image = cv2.imread(os.path.join(config[\"TRAIN_IMAGES_PATH\"], cancer_image_file_name), cv2.IMREAD_COLOR)[:, : , ::-1]\n",
    "cancer_image = cv2.resize(cancer_image, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "#others techniques likes otsu / clustering / other segmentation techniques in deep learning. / partial differential equation segmentation\n",
    "cancer_image_gray_scale = cv2.cvtColor(cancer_image, cv2.COLOR_RGB2GRAY)\n",
    "cancer_image_gray_scale =cv2.GaussianBlur(cancer_image_gray_scale, (5, 5), 0)\n",
    "\n",
    "otsu_threshold, image_result = cv2.threshold(\n",
    "    cancer_image_gray_scale, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,\n",
    ")\n",
    "\n",
    "print(\"Obtained threshold: \", otsu_threshold)\n",
    "\n",
    "segmented_image_cancer_image = cancer_image.copy()\n",
    "segmented_image_cancer_image[:, :, 0] = cancer_image[:, :, 0] * (cancer_image_gray_scale<otsu_threshold)\n",
    "segmented_image_cancer_image[:, :, 1] = cancer_image[:, :, 1] * (cancer_image_gray_scale<otsu_threshold)\n",
    "segmented_image_cancer_image[:, :, 2] = cancer_image[:, :, 2] * (cancer_image_gray_scale<otsu_threshold)\n",
    "\n",
    "fig, ax = plt.subplots(1, 7, figsize=(15, 15))\n",
    "\n",
    "ax[0].imshow(cancer_image)\n",
    "ax[1].imshow(cancer_image_gray_scale, \"gray\")\n",
    "ax[2].imshow(image_result, \"gray\")\n",
    "ax[3].imshow(segmented_image_cancer_image)\n",
    "ax[4].imshow(lbp_transformer.transform(segmented_image_cancer_image), \"gray\")\n",
    "ax[5].imshow(lbp_transformer.transform(cancer_image), \"gray\")\n",
    "ax[6].imshow(lbp_transformer.transform(cancer_image)*image_result, \"gray\")"
   ],
   "id": "7922732a7340327",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cancer_image_file_name = train_csv.query(\"target==0\").to_numpy()[2][0] + \".jpg\"\n",
    "\n",
    "cancer_image = cv2.imread(os.path.join(config[\"TRAIN_IMAGES_PATH\"], cancer_image_file_name), cv2.IMREAD_COLOR)[:, : , ::-1]\n",
    "cancer_image = cv2.resize(cancer_image, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "#others techniques likes otsu / clustering / other segmentation techniques in deep learning. / partial differential equation segmentation\n",
    "cancer_image_gray_scale = cv2.cvtColor(cancer_image, cv2.COLOR_RGB2GRAY)\n",
    "cancer_image_gray_scale =cv2.GaussianBlur(cancer_image_gray_scale, (5, 5), 0)\n",
    "\n",
    "otsu_threshold, image_result = cv2.threshold(\n",
    "    cancer_image_gray_scale, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU,\n",
    ")\n",
    "\n",
    "print(\"Obtained threshold: \", otsu_threshold)\n",
    "\n",
    "segmented_image_cancer_image = cancer_image.copy()\n",
    "segmented_image_cancer_image[:, :, 0] = cancer_image[:, :, 0] * (cancer_image_gray_scale<otsu_threshold)\n",
    "segmented_image_cancer_image[:, :, 1] = cancer_image[:, :, 1] * (cancer_image_gray_scale<otsu_threshold)\n",
    "segmented_image_cancer_image[:, :, 2] = cancer_image[:, :, 2] * (cancer_image_gray_scale<otsu_threshold)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 15))\n",
    "\n",
    "ax[0].imshow(cancer_image)\n",
    "ax[1].imshow(cancer_image_gray_scale, \"gray\")\n",
    "ax[2].imshow(image_result, \"gray\")\n",
    "ax[3].imshow(segmented_image_cancer_image)"
   ],
   "id": "4ca2635027e2594",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Color\n",
    "\n",
    "Due to the variations between different skins colors this could lead to noise thus I will work with grayscale images."
   ],
   "id": "2a5effedff13b5c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Removing black bars",
   "id": "eab44564b9fbd62c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from prototypes.classical.segmentation.transformers import BlackBarsRemover, OtsuThresholdingSegmentation",
   "id": "ae282e670c4f4f75",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cancer_image.shape",
   "id": "a4847a93e4cee3b9",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from prototypes.classical.segmentation.transformers import BlackBarsRemover, OtsuThresholdingSegmentation\n",
    "\n",
    "\n",
    "cancer_image_file_name = train_csv.query(\"target==1\").to_numpy()[1][0] + \".jpg\"\n",
    "cancer_image = cv2.imread(os.path.join(config[\"TRAIN_IMAGES_PATH\"], cancer_image_file_name), cv2.IMREAD_COLOR)[:, : , ::-1]\n",
    "cancer_image = cv2.resize(cancer_image, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "cancer_image = cv2.cvtColor(cancer_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "def remove_black_bars(image):\n",
    "    image_without_black_bars = image.copy()\n",
    "    min_width = min_height = 0\n",
    "\n",
    "    for i in range(image.shape[0]):\n",
    "        if image[i, :].sum() < image.shape[0]:\n",
    "            min_height = i + 1\n",
    "\n",
    "    for j in range(image.shape[1]):\n",
    "        if image[:, j].sum() < image.shape[1]:\n",
    "            min_width = j\n",
    "    \n",
    "    return cv2.resize(image_without_black_bars[min_height:, min_width:], (image.shape[0], image.shape[1]), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "br = BlackBarsRemover()\n",
    "otsu_threshold = OtsuThresholdingSegmentation()\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 15))\n",
    "ax[0].imshow(cancer_image, \"gray\")\n",
    "ax[1].imshow(br.transform([cancer_image])[0], \"gray\")\n",
    "ax[2].imshow(otsu_threshold.transform(br.transform([cancer_image]))[0], \"gray\")\n",
    "erosion = cv2.erode(otsu_threshold.transform(br.transform([cancer_image]))[0], np.ones((3, 3)), iterations = 1)\n",
    "ax[3].imshow(erosion, \"gray\")"
   ],
   "id": "836e76f68f75579",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Batches",
   "id": "896f00a3a54972c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset = IsiCancerData(config_file=config)",
   "id": "171df56d2f7a7faf",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch = next(iter(dataset.get_next_batch()))",
   "id": "12136966fba3a1f3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch[0].shape, batch[1].shape",
   "id": "e301a97ca9fa4700",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "images_batches = []\n",
    "labels_batches = []\n",
    "\n",
    "for batch in tqdm(dataset.get_next_batch(), total=dataset.total_samples()):\n",
    "    images_batches.append(batch[0])\n",
    "    labels_batches.append(batch[1])"
   ],
   "id": "1d11f45d604d6670",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "images_batches[0].shape",
   "id": "1413c700ec508dff",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "images_batches[0][0].max()",
   "id": "d8a00e455160f89e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.imshow(images_batches[0][-1].astype(np.uint8)[:,:,::-1])",
   "id": "af72aa75bea1f67d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.imshow(images_batches[0][2].astype(np.uint8)[:,:,::-1])",
   "id": "f556ea992b9cac4b",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
