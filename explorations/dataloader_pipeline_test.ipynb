{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-24T16:01:23.554209Z",
     "start_time": "2024-08-24T16:01:23.429252Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "import PIL.Image\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from prototypes.classical.descriptors.vetorizer import GaborAttentionLBPVectors\n",
    "from prototypes.deeplearning.dataloader.IsicDataLoader import LoadDataVectors, LoadPreProcessVectors\n",
    "import albumentations as A\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "with open(\"../config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Augmentation",
   "id": "8ca011963032d496"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T16:01:23.752268Z",
     "start_time": "2024-08-24T16:01:23.731119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Augmentation per sample\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class Augmentation():\n",
    "    def __init__(self, augmentation_transform):\n",
    "        self.augmentation_transform = augmentation_transform\n",
    "\n",
    "    def __call__(self, sample):        \n",
    "        return Image.fromarray(self.augmentation_transform(image=np.array(sample))[\"image\"])\n",
    "\n",
    "augmentation_transform = A.Compose([\n",
    "    A.CLAHE(p=0.4),\n",
    "    A.RandomRotate90(p=0.7),\n",
    "    A.Transpose(p=0.6),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n",
    "    A.Blur(blur_limit=3),\n",
    "    A.OpticalDistortion(p=0.5),\n",
    "    A.GridDistortion(p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    # Vit transform\n",
    "    # A.Resize(224, 224),\n",
    "    # A.ToFloat(always_apply=True),\n",
    "    # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "transform_augmentation = torchvision.transforms.Compose([Augmentation(augmentation_transform=augmentation_transform),\n",
    "                                                          torchvision.models.ViT_B_16_Weights.IMAGENET1K_SWAG_LINEAR_V1.transforms()])"
   ],
   "id": "55b637b2ae4d15f4",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T16:01:34.269663Z",
     "start_time": "2024-08-24T16:01:23.883748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = LoadDataVectors(hd5_file_path=os.path.join(config[\"DATASET_PATH\"], \"train-image.hdf5\"),\n",
    "                               metadata_csv_path=os.path.join(config[\"DATASET_PATH\"], \"train-metadata.csv\"),\n",
    "                               metadata_columns=config[\"METADATA_COLUMNS\"].split(\"\\t\"),\n",
    "                               transform=transform_augmentation)"
   ],
   "id": "ba17833eb86ef3f",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T16:01:34.303400Z",
     "start_time": "2024-08-24T16:01:34.270703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train, val = torch.utils.data.random_split(dataloader,\n",
    "                                           [config[\"TRAIN_SPLIT\"], 1 - config[\"TRAIN_SPLIT\"]])"
   ],
   "id": "fe22d44bd6343a49",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T16:01:34.405015Z",
     "start_time": "2024-08-24T16:01:34.304360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# val.transforms = torchvision.models.ViT_B_16_Weights.IMAGENET1K_SWAG_LINEAR_V1.transforms()\n",
    "feature_vector, metadata, target = next(iter(train))"
   ],
   "id": "b37e58b8e66bf751",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T16:01:34.426579Z",
     "start_time": "2024-08-24T16:01:34.406457Z"
    }
   },
   "cell_type": "code",
   "source": "len(metadata)",
   "id": "fb522c51c031c032",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.imshow((feature_vector.transpose(0, 2).numpy()))",
   "id": "a7e961680ef5e704",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "next(iter(val))",
   "id": "57e881614f6fffee",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T15:49:12.368482Z",
     "start_time": "2024-08-24T15:49:12.186577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val.dataset.transform = transform_augmentation\n",
    "\n",
    "feature_vector = next(iter(val))\n",
    "\n",
    "plt.imshow((feature_vector.transpose(0, 2).numpy()))"
   ],
   "id": "54b2ba5630581a62",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vector_dataloader = torch.utils.data.DataLoader(train, batch_size=8, shuffle=True, num_workers=8)",
   "id": "7f822e0a7a0dd0c5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "next(iter(vector_dataloader))[0][0].numpy()",
   "id": "7a26da9e3f1bc77a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ae15382d70de20c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "preprocess_vectors = LoadPreProcessVectors(dataset_base_path=\"../feature_vectors\", feature_name=\"gabor_attention_maps\", target_index=[0], dimensions=128)",
   "id": "51366c5f2c5dbc55",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x, y = next(iter(preprocess_vectors))",
   "id": "2c7d91829e59213c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x.shape, y.shape",
   "id": "ace5f20f12a6c79f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y",
   "id": "f830af9850acc3fb",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2ba2cd8a94c266a0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a3aa2f44d384c21d",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
